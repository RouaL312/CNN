{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from audio import read_mfcc\n",
    "from batcher import sample_from_mfcc\n",
    "from constants import SAMPLE_RATE, NUM_FRAMES\n",
    "from conv_models import DeepSpeakerModel\n",
    "from test import batch_cosine_similarity\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Reproducible results.\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "# Define the model here.\n",
    "model = DeepSpeakerModel()\n",
    "\n",
    "# Load the checkpoint.\n",
    "model.m.load_weights('ResCNN_triplet_training_checkpoint_265.h5', by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input file loaded\n"
     ]
    }
   ],
   "source": [
    "# Sample some input for WAV file.\n",
    "mfcc_001 = sample_from_mfcc(read_mfcc('C:/Users/laadouz/Desktop/speaker recognition finale work/data/speakers/roua_laadouz.wav', SAMPLE_RATE), NUM_FRAMES)\n",
    "\n",
    "# Call the model to get the embeddings of shape (1, 512) for the input file.\n",
    "predict_001 = model.m.predict(np.expand_dims(mfcc_001, axis=0))\n",
    "\n",
    "print (\"input file loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.06160881], dtype=float32), array([0.21131551], dtype=float32), array([0.46583757], dtype=float32), array([-0.16286714], dtype=float32), array([0.94165355], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "                              \n",
    "path = 'speakers'\n",
    "\n",
    "for filename in glob.glob(os.path.join('C:/Users/laadouz/Desktop/speaker recognition finale work/data/speakers/','*.wav')) :\n",
    "    mfcc_002 = sample_from_mfcc(read_mfcc(filename, SAMPLE_RATE), NUM_FRAMES)\n",
    "    predict_002 = model.m.predict(np.expand_dims(mfcc_002, axis=0))\n",
    "    similarity = batch_cosine_similarity(predict_001, predict_002)\n",
    "    results.append (similarity)\n",
    "    \n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94165355]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "max_val = max(results)\n",
    "print (max_val)\n",
    "index_speaker = results.index(max_val) + 1\n",
    "print (index_speaker) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le locuteur est :\n",
      "ID : 5 Name: roua_laadouz.wav Full Path: C:\\Users\\laadouz\\Desktop\\speaker recognition finale work\\data\\speakers\\roua_laadouz.wavLast Modified: 16/05/20 12:54:07Extension : .wav Size file: 441078 Profession: student Gender: F\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#list the files\n",
    "filelist= pd.read_csv('C:/Users/laadouz/Desktop/speaker recognition finale work/data/speakerdata.csv',encoding = \"ISO-8859-1\") \n",
    "\n",
    "#read them into pandas\n",
    "df_speaker = pd.DataFrame(filelist)\n",
    "\n",
    "data = filelist[['id','Name','Full Path','Last Modified','Extension','Size','profession','Gender']]\n",
    "\n",
    "data['path'] = 'ID : '+data['id'].astype(str)+' Name: '+data['Name'].astype(str)+' Full Path: '+data['Full Path'].astype(str)+'Last Modified: '+data['Last Modified'].astype(str)+'Extension : '+data['Extension'].astype(str)+' Size file: '+data['Size'].astype(str)+' Profession: '+data['profession'].astype(str)+' Gender: '+data['Gender'].astype(str)\n",
    "\n",
    "print ( \"le locuteur est :\")\n",
    "print(data['path'][index_speaker-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tensorflow-session': conda)",
   "language": "python",
   "name": "python37664bittensorflowsessionconda5dac529a3d4d42d486c8dc1dfcc77c9c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
